{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bdb5ca24",
   "metadata": {},
   "source": [
    "# IMPORT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49f26651",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Installation des dépendances pour Google Colab\n",
    "# # On utilise [extra] pour SB3 (TensorBoard support) et [box2d] pour l'environnement LunarLander\n",
    "# !pip install \"stable-baselines3[extra]\" \"gymnasium[box2d]\" tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01b66eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from stable_baselines3 import DQN\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "import gymnasium as gym\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f00732a",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95632fe1",
   "metadata": {},
   "source": [
    "# EXPLORATION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a180885",
   "metadata": {},
   "source": [
    "## LunarLander environment creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "652c01c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "LunarLander_env = gym.make('LunarLander-v3')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4745b311",
   "metadata": {},
   "source": [
    "## LunarLander online documentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0feb9c28",
   "metadata": {},
   "source": [
    "### <u>Description</u>\n",
    "This environment is a classic rocket trajectory optimization problem. According to Pontryagin’s maximum principle, it is optimal to fire the engine at full throttle or turn it off. This is the reason why this environment has discrete actions: engine on or off.\n",
    "\n",
    "There are two environment versions: discrete or continuous. The landing pad is always at coordinates (0,0). The coordinates are the first two numbers in the state vector. Landing outside of the landing pad is possible. Fuel is infinite, so an agent can learn to fly and then land on its first attempt.  \n",
    "![Animation du Lander](https://gymnasium.farama.org/_images/lunar_lander.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87f8f3c8",
   "metadata": {},
   "source": [
    "### <u>Actions</u> \n",
    "\n",
    "There are four discrete actions available:\n",
    "\n",
    "- 0: do nothing\n",
    "- 1: fire left orientation engine\n",
    "- 2: fire main engine\n",
    "- 3: fire right orientation engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7121b7ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observation Space : Discrete(4)\n",
      "Observation shape : ()\n",
      "Observation sample : 3\n"
     ]
    }
   ],
   "source": [
    "print(f\"Observation Space : {LunarLander_env.action_space}\")\n",
    "print(f\"Observation shape : {LunarLander_env.action_space.shape}\")\n",
    "print(f\"Observation sample : {LunarLander_env.action_space.sample()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a53cc662",
   "metadata": {},
   "source": [
    "### <u>Environment</u>\n",
    "\n",
    "The state is an 8-dimensional vector:\n",
    "\n",
    "- Coordinates of the lander in x & y (2)\n",
    "- Linear velocities in x & y (2)\n",
    "- angle (1)\n",
    "- angular velocity (1)\n",
    "- two booleans that represent whether each leg is in contact with the ground or not. (2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b27a08b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observation Space : Box([ -2.5        -2.5       -10.        -10.         -6.2831855 -10.\n",
      "  -0.         -0.       ], [ 2.5        2.5       10.        10.         6.2831855 10.\n",
      "  1.         1.       ], (8,), float32)\n",
      "Observation shape : (8,)\n",
      "Observation sample : [ 1.3324467   1.917008   -1.4704447  -3.2587903  -5.6439013   8.102522\n",
      "  0.78382874  0.8964716 ]\n"
     ]
    }
   ],
   "source": [
    "print(f\"Observation Space : {LunarLander_env.observation_space}\")\n",
    "print(f\"Observation shape : {LunarLander_env.observation_space.shape}\")\n",
    "print(f\"Observation sample : {LunarLander_env.observation_space.sample()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97badfab",
   "metadata": {},
   "source": [
    "### <u>Rewards</u> \n",
    "After every step a reward is granted. The total reward of an episode is the sum of the rewards for all the steps within that episode.\n",
    "\n",
    "For each step, the reward:\n",
    "\n",
    "- is increased/decreased the closer/further the lander is to the landing pad.\n",
    "- is increased/decreased the slower/faster the lander is moving.\n",
    "- is decreased the more the lander is tilted (angle not horizontal).\n",
    "- is increased by 10 points for each leg that is in contact with the ground.\n",
    "- is decreased by 0.03 points each frame a side engine is firing.\n",
    "- is decreased by 0.3 points each frame the main engine is firing.\n",
    "- The episode receive an additional reward of -100 or +100 points for crashing or landing safely respectively.\n",
    "\n",
    "An episode is considered a solution if it scores at least 200 points."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47f0d780",
   "metadata": {},
   "source": [
    "**We will choose de discrete version of LunarLander.**  \n",
    "**It will allows us to explore in an easy way how the environment adn action behave.**  \n",
    "**We will for sure use DQN model (which is discrete) to control the spaceship** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13e70192",
   "metadata": {},
   "source": [
    "## DQN model declaration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "528445f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DQN_model = DQN(\n",
    "#     policy = \"MlpPolicy\", # classic nn\n",
    "#     env = LunarLander_env, \n",
    "#     verbose = 1,\n",
    "#     learning_rate = 1e-3,\n",
    "#     buffer_size=50000,\n",
    "#     learning_starts=5000,\n",
    "#     exploration_fraction=0.6,\n",
    "#     exploration_final_eps=0.05,\n",
    "#     device=\"auto\"\n",
    "\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c124913",
   "metadata": {},
   "source": [
    "# TRAINING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "712d79bf",
   "metadata": {},
   "source": [
    "## Training DQN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4d94644a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"lancement de l'entrainement...\")\n",
    "\n",
    "# DQN_model.learn(total_timesteps=25000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ec01f11",
   "metadata": {},
   "source": [
    "## Evaluate baseline DQN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fa96d558",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Evaluation en cours...\")\n",
    "# mean_reward, std_reward = evaluate_policy(DQN_model,LunarLander_env,n_eval_episodes=50)\n",
    "# print(f\"Moyenne {mean_reward} | +- {std_reward}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d329892c",
   "metadata": {},
   "source": [
    "**Le modèle de base obtient un reward de -102 ± 139. Ce score servira de référence pour l'optimisation**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a3827b0",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d6b11c3",
   "metadata": {},
   "source": [
    "# OPTIMISATION HYPERPARAMETERS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2161ac15",
   "metadata": {},
   "source": [
    "## Baseline model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edececfe",
   "metadata": {},
   "source": [
    "### Baseline params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "29c457bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASELINE_LR = 1e-3\n",
    "BASELINE_BS = 50000\n",
    "BASELINE_EF = 0.6\n",
    "BASELINE_G = 0.99\n",
    "BASELINE_LS = 5000\n",
    "TIME_STEPS = 300000 # Augmenté de 25k à 100k pour une meilleure visibilité des performances\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "59389391",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = \"../logs/dqn_LunarLander_v1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b74971f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "optimized_DQN_model = DQN(    \n",
    "    policy = \"MlpPolicy\",\n",
    "    env = LunarLander_env, \n",
    "    verbose = 0,\n",
    "    tensorboard_log = log_dir,\n",
    "    learning_rate = BASELINE_LR,\n",
    "    buffer_size=BASELINE_BS,\n",
    "    learning_starts=BASELINE_LS,\n",
    "    exploration_fraction=BASELINE_EF,\n",
    "    gamma= BASELINE_G,\n",
    "    device=\"cuda\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "93631ea0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.dqn.dqn.DQN at 0x17e34c8dfd0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimized_DQN_model.learn(total_timesteps=TIME_STEPS, tb_log_name=\"Baseline\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8b98ba8",
   "metadata": {},
   "source": [
    "## Learning rate optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61e5751a",
   "metadata": {},
   "source": [
    "### Learning rate to test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ffb5dfe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rates = [1e-1, 1e-2, 1e-4, 1e-5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c5c39e1",
   "metadata": {},
   "source": [
    "### Learning rates loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f63258",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">c:\\Users\\Fabien\\Desktop\\OC\\P11\\AstroDynamics\\.venv\\Lib\\site-packages\\rich\\live.py:260: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "c:\\Users\\Fabien\\Desktop\\OC\\P11\\AstroDynamics\\.venv\\Lib\\site-packages\\rich\\live.py:260: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " --- Start learning for a learning rate set at 0.1 ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " --- Start learning for a learning rate set at 0.01 ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " --- Start learning for a learning rate set at 0.0001 ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " --- Start learning for a learning rate set at 1e-05 ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for learning_rate in learning_rates:\n",
    "    run_name = f\"lr_{learning_rate}\"\n",
    "    print(f\" --- Start learning for a learning rate set at {learning_rate} ---\")\n",
    "\n",
    "    model = DQN(\n",
    "        \"MlpPolicy\",\n",
    "        LunarLander_env,\n",
    "        learning_rate=learning_rate,\n",
    "        buffer_size=BASELINE_BS,\n",
    "        learning_starts=BASELINE_LS,\n",
    "        gamma= BASELINE_G,\n",
    "        exploration_fraction = BASELINE_EF,\n",
    "        device=\"cuda\",\n",
    "        tensorboard_log=log_dir\n",
    "    )\n",
    "\n",
    "    model.learn(total_timesteps=TIME_STEPS,tb_log_name=run_name, progress_bar=True)\n",
    "\n",
    "    model.save(f\"../data/model/dqn_lunarlander_{run_name}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8243ec2",
   "metadata": {},
   "source": [
    "## Exploration_fraction optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0caef7e8",
   "metadata": {},
   "source": [
    "### Exploration fraction to test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e609ede5",
   "metadata": {},
   "outputs": [],
   "source": [
    "exploration_fractions = [0.1,0.4,0.7,0.9]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b3e947",
   "metadata": {},
   "source": [
    "### exploration fraction loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d886bf0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " --- Start learning for a exploration fraction set at 0.1 ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " --- Start learning for a exploration fraction set at 0.4 ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " --- Start learning for a exploration fraction set at 0.7 ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " --- Start learning for a exploration fraction set at 0.9 ---\n"
     ]
    }
   ],
   "source": [
    "for exploration_fraction in exploration_fractions:\n",
    "    run_name = f\"ef_{exploration_fraction}\"\n",
    "    print(f\" --- Start learning for a exploration fraction set at {exploration_fraction} ---\")\n",
    "\n",
    "    model = DQN(\n",
    "        \"MlpPolicy\",\n",
    "        LunarLander_env,\n",
    "        learning_rate=BASELINE_LR,\n",
    "        buffer_size=BASELINE_BS,\n",
    "        learning_starts=BASELINE_LS,\n",
    "        gamma= BASELINE_G,\n",
    "        exploration_fraction = exploration_fraction,\n",
    "        device=\"cuda\",\n",
    "        tensorboard_log=log_dir\n",
    "    )\n",
    "\n",
    "    model.learn(total_timesteps=TIME_STEPS,tb_log_name=run_name, progress_bar=True)\n",
    "\n",
    "    model.save(f\"../data/model/dqn_lunarlander_{run_name}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a680d659",
   "metadata": {},
   "source": [
    "## Gamma optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c2d8461",
   "metadata": {},
   "source": [
    "### Gamma to test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f5e166ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "gammas = [0.8,0.9,0.95,0.97]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "915f25e8",
   "metadata": {},
   "source": [
    "### gamma loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe0fdb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " --- Start learning for a gamma set at 0.8 ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">c:\\Users\\Fabien\\Desktop\\OC\\P11\\AstroDynamics\\.venv\\Lib\\site-packages\\rich\\live.py:260: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "c:\\Users\\Fabien\\Desktop\\OC\\P11\\AstroDynamics\\.venv\\Lib\\site-packages\\rich\\live.py:260: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " --- Start learning for a gamma set at 0.9 ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " --- Start learning for a gamma set at 0.95 ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " --- Start learning for a gamma set at 0.97 ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for gamma in gammas:\n",
    "    run_name = f\"g_{gamma}\"\n",
    "    print(f\" --- Start learning for a gamma set at {gamma} ---\")\n",
    "\n",
    "    model = DQN(\n",
    "        \"MlpPolicy\",\n",
    "        LunarLander_env,\n",
    "        learning_rate=BASELINE_LR,\n",
    "        buffer_size=BASELINE_BS,\n",
    "        learning_starts=BASELINE_LS,\n",
    "        gamma= gamma,\n",
    "        exploration_fraction = BASELINE_EF,\n",
    "        device=\"cuda\",\n",
    "        tensorboard_log=log_dir\n",
    "    )\n",
    "\n",
    "    model.learn(total_timesteps=TIME_STEPS,tb_log_name=run_name, progress_bar=True)\n",
    "\n",
    "    model.save(f\"../data/model/dqn_lunarlander_{run_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82da9672",
   "metadata": {},
   "source": [
    "## Buffer_size optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1baa4acf",
   "metadata": {},
   "source": [
    "### buffer size to test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6c6c934a",
   "metadata": {},
   "outputs": [],
   "source": [
    "buffer_sizes = [10000,50000,100000,500000]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9da0e75a",
   "metadata": {},
   "source": [
    "### buffer size loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0d3e277d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " --- Start learning for a buffer size set at 10000 ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " --- Start learning for a buffer size set at 50000 ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " --- Start learning for a buffer size set at 100000 ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " --- Start learning for a buffer size set at 500000 ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for buffer_size in buffer_sizes:\n",
    "    run_name = f\"bs_{buffer_size}\"\n",
    "    print(f\" --- Start learning for a buffer size set at {buffer_size} ---\")\n",
    "\n",
    "    model = DQN(\n",
    "        \"MlpPolicy\",\n",
    "        LunarLander_env,\n",
    "        learning_rate=BASELINE_LR,\n",
    "        buffer_size=buffer_size,\n",
    "        learning_starts=BASELINE_LS,\n",
    "        gamma= BASELINE_G,\n",
    "        exploration_fraction = BASELINE_EF,\n",
    "        device=\"cuda\",\n",
    "        tensorboard_log=log_dir\n",
    "    )\n",
    "\n",
    "    model.learn(total_timesteps=TIME_STEPS,tb_log_name=run_name, progress_bar=True)\n",
    "\n",
    "    model.save(f\"../data/model/dqn_lunarlander_{run_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de6b196e",
   "metadata": {},
   "source": [
    "## Best hyper params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6dc479c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_HP_DQN = DQN(    \n",
    "    policy = \"MlpPolicy\",\n",
    "    env = LunarLander_env, \n",
    "    verbose = 0,\n",
    "    tensorboard_log = log_dir,\n",
    "    learning_rate = 1e-3,\n",
    "    buffer_size=100000,\n",
    "    learning_starts=BASELINE_LS,\n",
    "    exploration_fraction=0.2,\n",
    "    gamma= 0.99,\n",
    "    device=\"cuda\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9152357b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Fabien\\Desktop\\OC\\P11\\AstroDynamics\\.venv\\Lib\\site-packages\\stable_baselines3\\common\\save_util.py:284: UserWarning: Path '..\\data\\model' does not exist. Will create it.\n",
      "  warnings.warn(f\"Path '{path.parent}' does not exist. Will create it.\")\n"
     ]
    }
   ],
   "source": [
    "best_HP_DQN.learn(total_timesteps=1000000, tb_log_name=\"best_HP\")\n",
    "# On utilise un nom de fichier explicite pour éviter d'utiliser le run_name de la boucle précédente\n",
    "best_HP_DQN.save(\"../data/model/dqn_lunarlander_best_HP\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93ac68ee",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89cd2d36",
   "metadata": {},
   "source": [
    "# VISUALIZATION (TENSORBOARD)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74d7ca22",
   "metadata": {},
   "source": [
    "# EVALUATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a2d1983c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Fabien\\Desktop\\OC\\P11\\AstroDynamics\\.venv\\Lib\\site-packages\\stable_baselines3\\common\\evaluation.py:70: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Évaluation du modèle chargé en cours...\n",
      "Reward moyen : 232.27 +/- 54.73\n"
     ]
    }
   ],
   "source": [
    "# Chargement du meilleur modèle\n",
    "model_path = \"../data/model/dqn_lunarlander_best_HP\"\n",
    "loaded_model = DQN.load(model_path, env=LunarLander_env)\n",
    "\n",
    "print(\"Évaluation du modèle chargé en cours...\")\n",
    "mean_reward, std_reward = evaluate_policy(loaded_model, LunarLander_env, n_eval_episodes=100, deterministic=True)\n",
    "\n",
    "print(f\"Reward moyen : {mean_reward:.2f} +/- {std_reward:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a845c0a6",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5d2f38eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6008 (pid 31216), started 5:27:07 ago. (Use '!kill 31216' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-35761eeda20299ba\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-35761eeda20299ba\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6008;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir ../logs/dqn_LunarLander_v1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33d5ce05",
   "metadata": {},
   "source": [
    "##"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
