# üöÄ AstroDynamics ‚Äî Eagle-1 Atterrissage Automatis√©

[![Python](https://img.shields.io/badge/Python-3.13+-blue.svg?logo=python&logoColor=white)](https://www.python.org/)
[![FastAPI](https://img.shields.io/badge/FastAPI-0.129+-green.svg?logo=fastapi&logoColor=white)](https://fastapi.tiangolo.com/)
[![Streamlit](https://img.shields.io/badge/Streamlit-1.54+-red.svg?logo=streamlit&logoColor=white)](https://streamlit.io/)
[![Stable Baselines3](https://img.shields.io/badge/Stable_Baselines3-2.7+-orange.svg)](https://stable-baselines3.readthedocs.io/)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.10+-EE4C2C.svg?logo=pytorch&logoColor=white)](https://pytorch.org/)
[![Gymnasium](https://img.shields.io/badge/Gymnasium-1.2+-purple.svg)](https://gymnasium.farama.org/)

> **D√©p√¥t GitHub recommand√© :** [`DQN-LunarLander-FastAPI-Streamlit`](https://github.com/RandomFab/DQN-LunarLander-FastAPI-Streamlit)

**Entra√Ænement et d√©ploiement d'un agent DQN (Deep Q-Network) capable d'atterrir de mani√®re autonome sur la surface lunaire, dans l'environnement `LunarLander-v3` de Gymnasium.**

<p align="center">
  <img src="images/landing_demo.gif" alt="D√©monstration de l'atterrissage autonome" width="480">
</p>

---

## üéØ Objectif du projet

Ce projet explore l'**apprentissage par renforcement** (Reinforcement Learning) appliqu√© au contr√¥le d'un vaisseau spatial. Un agent DQN apprend, par essais-erreurs, √† ma√Ætriser ses r√©acteurs pour se poser en douceur sur un pad d'atterrissage.

Le projet comprend :
- Un **notebook d'entra√Ænement** avec optimisation syst√©matique des hyperparam√®tres
- Une **API FastAPI** servant le mod√®le entra√Æn√© pour l'inf√©rence
- Une **application Streamlit** permettant de visualiser l'agent en action et d'explorer ses d√©cisions

---

## ‚ú® Fonctionnalit√©s

- ‚úÖ Entra√Ænement d'un agent DQN avec **Stable Baselines 3** et suivi via **TensorBoard**
- ‚úÖ Optimisation s√©quentielle de 4 hyperparam√®tres : Learning Rate, Exploration Fraction, Gamma, Buffer Size
- ‚úÖ API REST pour l'inf√©rence unitaire (`/predict`) et en batch (`/predict_batch`)
- ‚úÖ Interface Streamlit avec **pilotage en temps r√©el** et **t√©l√©m√©trie** (score, altitude)
- ‚úÖ **Carte de d√©cisions interactive** (Policy Map) : visualisation des actions de l'IA selon la position du vaisseau avec des sliders pour les param√®tres dynamiques
- ‚úÖ Courbe d'apprentissage extraite directement des logs TensorBoard via Pandas

---

## üìä Architecture du projet

```mermaid
graph TB
    subgraph Entra√Ænement
        NB[üìì Notebook Training] -->|Stable Baselines 3| MODEL[üß† Mod√®le DQN .zip]
        NB -->|TensorBoard| LOGS[üìä Logs tfevents]
    end

    subgraph D√©ploiement Local
        MODEL -->|Chargement au d√©marrage| API[‚ö° API FastAPI :8000]
        API -->|/predict| APP_PILOT[üéÆ Pilotage Streamlit]
        API -->|/predict_batch| APP_DASH[üìä Dashboard Streamlit]
        LOGS -->|extract_logs.py| APP_DASH
    end

    subgraph Application Streamlit :8501
        APP_PILOT
        APP_DASH
    end
```

```mermaid
sequenceDiagram
    participant U as üë§ Utilisateur
    participant ST as üñ•Ô∏è Streamlit
    participant API as ‚ö° FastAPI
    participant M as üß† Mod√®le DQN
    participant ENV as üåô LunarLander

    U->>ST: Clique "Lancer la mission"
    ST->>ENV: reset()
    loop Chaque pas de simulation
        ST->>API: POST /predict {state: [8 floats]}
        API->>M: model.predict(state)
        M-->>API: action (0-3)
        API-->>ST: {action: 2}
        ST->>ENV: env.step(action)
        ENV-->>ST: observation, reward, done
        ST->>U: Affiche frame + t√©l√©m√©trie
    end
    ST->>U: Score final + R√©sultat mission
```

---

## üìÅ Structure des Fichiers

```
AstroDynamics/
‚îÇ
‚îú‚îÄ‚îÄ üìÇ src/
‚îÇ   ‚îú‚îÄ‚îÄ üé® app/                    # Interface utilisateur Streamlit
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ app.py                 # Point d'entr√©e + routage des pages
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ interface.py           # Page Pilotage : simulation en temps r√©el
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ dashboard.py           # Page Dashboard : carte de d√©cisions + courbe d'apprentissage
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ ‚ö° api/                    # API REST FastAPI
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ main.py                # Routes : /health, /predict, /predict_batch, /model_status
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ schemas.py             # Sch√©mas Pydantic (Observation, PredictionResponse)
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ üß† model/                  # Service m√©tier du mod√®le
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ model_service.py       # Chargement DQN + inf√©rence
‚îÇ   ‚îÇ
‚îÇ   ‚îî‚îÄ‚îÄ üîß scripts/                # Utilitaires
‚îÇ       ‚îî‚îÄ‚îÄ extract_logs.py        # Extraction des logs TensorBoard ‚Üí Pandas DataFrame
‚îÇ
‚îú‚îÄ‚îÄ üìÇ config/
‚îÇ   ‚îî‚îÄ‚îÄ logger.py                  # Configuration du logging
‚îÇ
‚îú‚îÄ‚îÄ üìÇ data/
‚îÇ   ‚îî‚îÄ‚îÄ üìÇ model/                  # Mod√®les entra√Æn√©s (.zip Stable Baselines 3)
‚îÇ       ‚îú‚îÄ‚îÄ dqn_lunarlander_best_HP.zip
‚îÇ       ‚îú‚îÄ‚îÄ dqn_lunarlander_lr_*.zip
‚îÇ       ‚îú‚îÄ‚îÄ dqn_lunarlander_ef_*.zip
‚îÇ       ‚îú‚îÄ‚îÄ dqn_lunarlander_g_*.zip
‚îÇ       ‚îî‚îÄ‚îÄ dqn_lunarlander_bs_*.zip
‚îÇ
‚îú‚îÄ‚îÄ üìÇ logs/
‚îÇ   ‚îî‚îÄ‚îÄ üìÇ dqn_LunarLander_v1/    # Logs TensorBoard par run
‚îÇ       ‚îú‚îÄ‚îÄ Baseline_1/
‚îÇ       ‚îú‚îÄ‚îÄ best_HP_1/
‚îÇ       ‚îú‚îÄ‚îÄ lr_*/ ef_*/ g_*/ bs_*/
‚îÇ       ‚îî‚îÄ‚îÄ ...
‚îÇ
‚îú‚îÄ‚îÄ üìÇ notebooks/
‚îÇ   ‚îú‚îÄ‚îÄ Training_model.ipynb       # Notebook principal : exploration, entra√Ænement, optimisation HP
‚îÇ   ‚îî‚îÄ‚îÄ EDA_info_best_HP.ipynb     # Analyse des logs du meilleur mod√®le
‚îÇ
‚îú‚îÄ‚îÄ üìÇ images/                     # Visuels pour le README
‚îÇ   ‚îú‚îÄ‚îÄ landing_demo.gif           # GIF de l'atterrissage autonome
‚îÇ   ‚îú‚îÄ‚îÄ interface_pilotage.png     # Capture de l'interface de pilotage
‚îÇ   ‚îî‚îÄ‚îÄ dashboard_policy_map.png   # Capture du dashboard et de la carte de d√©cisions
‚îÇ
‚îú‚îÄ‚îÄ pyproject.toml                 # D√©pendances et configuration du projet (uv)
‚îú‚îÄ‚îÄ uv.lock                       # Lockfile des d√©pendances
‚îî‚îÄ‚îÄ .python-version                # Python 3.13
```

---

## Lancement Rapide (VS Code)

Ce projet inclut des **t√¢ches VS Code** pour un d√©marrage simplifi√©.

1.  Ouvrez la palette de commandes : `Ctrl+Shift+P` (ou `Cmd+Shift+P` sur Mac).
2.  Tapez `Tasks: Run Task`.
3.  Choisissez l'une des t√¢ches suivantes :
    - `Start API` : Lance le serveur FastAPI sur `http://localhost:8000`.
    - `Start Streamlit` : Lance l'application Streamlit sur `http://localhost:8501`.

Les services d√©marreront dans des terminaux int√©gr√©s.

---

## Le Notebook d'Entra√Ænement

Le fichier `notebooks/Training_model.ipynb` suit un pipeline structur√© :

### 1. Exploration de l'environnement
- Cr√©ation de l'environnement `LunarLander-v3` (version discr√®te, 4 actions)
- Documentation du vecteur d'√©tat (8 dimensions) et du syst√®me de r√©compenses

### 2. Entra√Ænement Baseline
- Mod√®le DQN initial avec hyperparam√®tres par d√©faut
- Score de r√©f√©rence : **-102 ¬± 139** (le vaisseau s'√©crase syst√©matiquement)

### 3. Optimisation des Hyperparam√®tres
Chaque hyperparam√®tre est optimis√© s√©quentiellement sur **300 000 timesteps** :

| Hyperparam√®tre | Valeurs test√©es | Meilleure valeur |
|:---|:---|:---|
| Learning Rate | 1e-1, 1e-2, 1e-4, 1e-5 | **1e-3** (baseline) |
| Exploration Fraction | 0.1, 0.4, 0.7, 0.9 | **0.2** |
| Gamma | 0.8, 0.9, 0.95, 0.97 | **0.99** (baseline) |
| Buffer Size | 10k, 50k, 100k, 500k | **100 000** |

### 4. Entra√Ænement final
- Mod√®le `best_HP` entra√Æn√© sur **1 000 000 timesteps** avec les meilleurs hyperparam√®tres
- √âvaluation sur 100 √©pisodes en mode d√©terministe

### 5. Visualisation
- Affichage de l'agent en action via une fen√™tre Pygame (`render_mode='human'`)

---

## ‚ö° API FastAPI

L'API charge le mod√®le DQN au d√©marrage via le m√©canisme `lifespan` de FastAPI.

### Endpoints disponibles

| M√©thode | Route | Description |
|:---|:---|:---|
| `GET` | `/health` | V√©rification de l'√©tat de l'API |
| `GET` | `/model_status` | V√©rifie si le mod√®le est charg√© en m√©moire |
| `POST` | `/load_model` | Rechargement manuel du mod√®le |
| `POST` | `/predict` | Pr√©diction d'une action √† partir d'un vecteur d'√©tat (8 floats) |
| `POST` | `/predict_batch` | Pr√©diction en batch (optimis√© numpy, id√©al pour la carte de d√©cisions) |

### Exemple d'appel

```bash
curl -X POST http://localhost:8000/predict \
  -H "Content-Type: application/json" \
  -d '{"state": [0.12, 1.45, 0.0, -0.1, 0.05, 0.0, 0, 0]}'
```

**R√©ponse :**
```json
{"action": 2}
```

> Actions : `0` = Rien, `1` = Moteur Gauche, `2` = Moteur Principal, `3` = Moteur Droit

---

## üñ•Ô∏è Application Streamlit

L'application comporte deux pages accessibles via la barre lat√©rale :

### üéÆ Pilotage
- Simulation en temps r√©el de l'atterrissage
- Rendu vid√©o de l'environnement LunarLander directement dans le navigateur
- T√©l√©m√©trie en direct : r√©compense totale, barre d'altitude
- R√©sultat de mission avec animation (ballons si score ‚â• 200)

<p align="center">
  <img src="images/Interface.png" alt="Interface de pilotage" width="700">
</p>

### üìä Dashboard
- **Carte de d√©cisions interactive** : grille 50√ó50 de positions (x, y) color√©e par action pr√©dite
- **Sliders dynamiques** : vitesse X/Y, position angulaire, vitesse angulaire pour explorer la politique de l'agent
- **Courbe d'apprentissage** : r√©compense moyenne au fil de l'entra√Ænement (extraite des logs TensorBoard)

<p align="center">
  <img src="images/Dashboard.png" alt="Dashboard - Carte des d√©cisions" width="700">
</p>

---

## üöÄ Installation & Lancement

### Pr√©requis

- Python **3.13+**
- [uv](https://docs.astral.sh/uv/) (gestionnaire de paquets)

### Installation

```bash
# Cloner le d√©p√¥t
git clone <url-du-repo>
cd AstroDynamics

# Installer les d√©pendances
uv sync
```

### Lancement

L'application n√©cessite **deux processus** en parall√®le :

```bash
# Terminal 1 : D√©marrer l'API (port 8000)
uv run uvicorn src.api.main:api --reload

# Terminal 2 : D√©marrer Streamlit (port 8501)
uv run streamlit run src/app/app.py
```

Puis ouvrir [http://localhost:8501](http://localhost:8501) dans le navigateur.

### TensorBoard (optionnel)

```bash
uv run python -m tensorboard.main --logdir logs/dqn_LunarLander_v1
```

---

## üß™ Conclusions

- L'agent DQN parvient √† **atterrir de mani√®re fiable** avec un score moyen sup√©rieur √† 200, ce qui qualifie l'environnement comme "r√©solu"
- L'optimisation s√©quentielle des hyperparam√®tres montre que le **Learning Rate** (1e-3) et le **Gamma** (0.99) de la baseline √©taient d√©j√† optimaux, tandis que l'**Exploration Fraction** (0.2) et le **Buffer Size** (100k) ont √©t√© affin√©s
- L'entra√Ænement prolong√© √† **1 million de timesteps** permet une convergence stable de la politique
- La **carte de d√©cisions** r√©v√®le que l'agent utilise principalement le moteur principal en altitude et les moteurs lat√©raux pour corriger sa trajectoire horizontale

---

## Auteur

**RandomFab** ‚Äî Fabien BARDOUIL
